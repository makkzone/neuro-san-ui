# This pipeline builds the images needed to run the unileaf
# cluster. Additionally it builds a wheel file that contains the
# required python dependencies for unileaf notebook use.
# The unileaf version is passed in as the git sha of the current commit
# for cases of merge to main. For the Release case, the unileaf version
# is the semver tag used to designate the release. This unileaf version value
# is then used as the identifer/label for everything built in this pipeline,
# including docker images for the unileaf service and the wheel file used to
# package the required dependencies for unileaf notebook users.
# Note that our ecr registries are configured
# for tag-immutability. Thus, if a pipeline is run and some image builds
# succeed and others fail, the entire pipeline cannot be re-run
# (at the same git-sha or release tag) without first going into our
# ecr and deleting the image builds that did succeed.

version: '1.0'
steps:
    main_clone:
        # Using a clone step name of "main-clone" insures that the default
        # working_directory of all other steps is where this clone happened.
        title: "Cloning repository"
        type: "git-clone"
        repo: "leaf-ai/unileaf"
        git: "github"
        # Supply the tag, git sha or branch name via CF variable.
        # The unileaf version is passed in as the git sha of the current commit
        # for cases of merge to main. For the Release case, the unileaf version
        # is the semver tag used to designate the release. This unileaf version value
        # is then used as the identifer/label for everything built in this pipeline,
        # including docker images for the unileaf service and the wheel file used to
        # package the required dependencies for unileaf notebook users.
        revision: ${{UNILEAF_VERSION}}

    preflight-pandas-check:
        description: "Get the current pandas version"
        type: "freestyle"
        image: alpine:3.13.1
        working_directory: ${{CF_VOLUME_PATH}}/unileaf
        commands:
            - cd build_scripts && ./pandas_check.sh

    ensure-python-git-pandas-exists:
        description: "Make sure the specified pandas version has a pre-built-image"
        type: freestyle
        image: "public.ecr.aws/q0i6b0q4/python-git-pandas:${{DEFAULT_NEUROAI_PYTHON_VERSION}}-${{DEFAULT_NEUROAI_GIT_VERSION}}-${{PANDAS_VERSION}}"
        commands:
            - echo "The required image exists"

    prepare_for_build:
        description: "Do any common preparation for tests"
        type: "freestyle"
        image: alpine:3.13.1
        commands:
            # Set up some variables

            # It's our experience the the CF_VOLUME can leak between builds
            # Attempt to do some isolation.
            - export TEMP_DIR_OUTSIDE_CONTAINER=${{CF_VOLUME_PATH}}/tmp/${{CF_BUILD_ID}}
            - mkdir -p ${TEMP_DIR_OUTSIDE_CONTAINER}

            # cf_export these variables so these vars can be used in later build steps
            - cf_export TEMP_DIR_OUTSIDE_CONTAINER

            # Temporarily atone for previous plugin sins that hint at CF_VOLUME leakage
            # between builds.
            # ??? This should be able to be deleted when our new-style codefresh is propagated
            - rm -rf leaf-common completion-service leaf-distributed leaf-server-common esp-sdk unileaf-util
            
    create-temp-git-creds-from-vault:
        title: "Get ephemeral GitHub creds"
        description: "Get temporary git credentials from vault server.
                      Create credential for use in docker secret with_creds_requirements"
        type: "freestyle"
        image: "vault:1.12.0"
        commands:
            # Login into Vault only once
            - >-
                vault login -address=${{VAULT}} -method=github token=${{VAULT_LOGIN}}
                | grep -Ev "(token |token_accessor)"
            # This section bears some explanation.
            #
            # In vault, access to our source repos is divided into "private" repos
            # and those that aren't private. To build our python based services, we provide
            # either one or both of these tokens to allow git access into the necessary repos.
            # The required repos vary based on which service, and this information is contained
            # in the relevant requirements.txt file.
            # 
            # In the python case, we have additional machinery to write this token directly into
            # a copy of the requirements file which is then passed into the docker build command as 
            # a docker secret. This token format is prepended with "x-access-token" which you'll see
            # below.
            #
            # For the ui-node and metadata-gateway builds, we require neuro-san as a dependency
            # (specifically, the agent.proto file) which we get from github for the specific
            # target version of that file. In this case, there is no prepended string before the actual token.
            # Since codefresh does not support docker build commands using the "env" format, we
            # provide this value in a file which is passed into the docker build command as a secret 
            # in a similar manner to the python services.

            # Get the ephemeral token for public repos for use in python service builds
            - EPHEMERAL_TOKEN=$(vault read -address=${{VAULT}} -field=token /github-secrets/token/repo-read)
            - cf_export EPHEMERAL_LEAF_SOURCE_CREDENTIALS="x-access-token:${EPHEMERAL_TOKEN}"

            # Write the not-private token to file for use in ui-node and metadata-gateway build
            - export LEAF_SOURCE_CREDENTIALS="${EPHEMERAL_TOKEN}"
            - echo ${LEAF_SOURCE_CREDENTIALS} > ${TEMP_DIR_OUTSIDE_CONTAINER}/LEAF_SOURCE_CREDENTIALS.txt
            - cf_export LEAF_SOURCE_CREDENTIALS="${EPHEMERAL_TOKEN}"

            # Get the ephemeral token for private repos for use in python service builds
            - EPHEMERAL_TOKEN=$(vault read -address=${{VAULT}} -field=token /github-private-secrets/token/repo-read)
            - cf_export EPHEMERAL_LEAF_PRIVATE_SOURCE_CREDENTIALS="x-access-token:${EPHEMERAL_TOKEN}"

    create-req-files-with-git-creds:
        title: "Create credentialed requirements files for secret build steps"
        type: "freestyle"
        image: python:${{DEFAULT_NEUROAI_PYTHON_VERSION}}-slim
        commands:
            - python build_scripts/requirements_handler.py
    
    generate_proto_stubs_for_ui:
      title: Generate proto stubs for ui
      description: Generate proto stubs for the frontend
      image: node:${{NODEJS_VERSION}}-alpine
      working_directory: ${{CF_VOLUME_PATH}}/unileaf/nextfront
      fail_fast: true
      commands:
        - apk add --quiet --no-progress --upgrade bash protobuf-dev git
        - yarn install
        - ./grpc/do_typescript_generate.sh

    # The memory required to build images is always increasing
    # and building all images in parallel was frequently hitting memory constraints
    # on our AWS CF nodes. So the builds are split into two steps to reduces the
    # necessary memory for a successful pipeline run. There is nothing special about
    # the ordering of the image builds.
    build-images-phase-1:
        type: parallel
        steps:

            run-submission:
                title: Build run submission server Docker image
                type: "build"
                image_name: "leaf/unileaf-run-submission"
                tag: ${{UNILEAF_VERSION}}
                build_arguments:
                    - UNILEAF_VERSION=${{UNILEAF_VERSION}}
                    - PYTHON_VERSION=${{DEFAULT_NEUROAI_PYTHON_VERSION}}
                    - GIT_VERSION=${{DEFAULT_NEUROAI_GIT_VERSION}}
                    - PANDAS_VERSION=${{PANDAS_VERSION}}
                dockerfile: "backend/runsubmission/service/Dockerfile"
                buildkit: true
                # Docker BuildKit has different output. This progress plain allows
                # us to see the 'old' style output which is useful.
                progress: "plain"
                # The src refers to our secret file on the host system. Within the
                # dockerfile we refer to the secret by id. By not providing a dst
                # the file ends up at the docker default of /run/secrets/<id>
                # This same file is used for run-submission and data-profiler.
                #
                # AWS_CREDS is needed for a build-time step that downloads wheel files
                # that are made available as an artifact with every run.
                secrets:
                    - id=with_creds_requirements,src=${{RUN_SUBMISSION_WITH_CREDS_REQUIREMENTS}}
                    - id=aws_creds,src=${{AWS_CREDS}}

            inference-server:
                title: Build inference server Docker image
                type: "build"
                image_name: "leaf/unileaf-inference-server"
                tag: ${{UNILEAF_VERSION}}
                build_arguments:
                    - UNILEAF_VERSION=${{UNILEAF_VERSION}}
                    - PYTHON_VERSION=${{DEFAULT_NEUROAI_PYTHON_VERSION}}
                dockerfile: "backend/inferenceserver/Dockerfile"
                buildkit: true
                progress: "plain"
                secrets:
                    - id=with_creds_requirements,src=${{INFERENCE_SERVER_WITH_CREDS_REQUIREMENTS}}

            task-server:
                title: Build task server Docker image
                type: "build"
                image_name: "leaf/unileaf-task-server"
                tag: ${{UNILEAF_VERSION}}
                build_arguments:
                    - UNILEAF_VERSION=${{UNILEAF_VERSION}}
                    - PYTHON_VERSION=${{DEFAULT_NEUROAI_PYTHON_VERSION}}
                dockerfile: "backend/taskserver/Dockerfile"
                buildkit: true
                progress: "plain"
                secrets:
                    - id=with_creds_requirements,src=${{TASK_SERVER_WITH_CREDS_REQUIREMENTS}}

            ui-node-build:
                title: Build ui-node Docker image
                image_name: "leaf/unileaf-ui-node"
                type: build
                buildkit: true
                progress: "plain"
                dockerfile: ./Dockerfile
                working_directory: ./nextfront
                # Regarding the GATEWAY value (for any and all environments):
                # In the current implementation, an AWS load balancer routes
                # the requests to the gateway, based on requests containing /api/v1,
                # thus obviating the need to have an externally exposed gateway service.
                build_arguments:
                    - NODEJS_VERSION=${{NODEJS_VERSION}}
                    - UNILEAF_VERSION=${{UNILEAF_VERSION}}
                    # Provide either "old" or "new" to switch between
                    # model serving versions.
                    - MODEL_SERVING_VERSION=${{MODEL_SERVING_VERSION}}
                tag: "${{UNILEAF_VERSION}}"
                secrets:
                    - id=LEAF_SOURCE_CREDENTIALS,src=${{TEMP_DIR_OUTSIDE_CONTAINER}}/LEAF_SOURCE_CREDENTIALS.txt

    build-images-phase-2:
        type: parallel
        steps:
            mdserver-gateway-build:
                title: Build mdserver-gateway Docker image
                type: build
                dockerfile: cmd/Dockerfile
                target: ${{build_target}}
                tag: ${{UNILEAF_VERSION}}
                image_name: "leaf/unileaf-gateway-mdserver"
                buildkit: true
                progress: "plain"
                secrets:
                    - id=LEAF_SOURCE_CREDENTIALS,src=${{TEMP_DIR_OUTSIDE_CONTAINER}}/LEAF_SOURCE_CREDENTIALS.txt

            data-profiler-build:
                title: Build data-profiler Docker image
                type: build
                image_name: "leaf/unileaf-data-profiler"
                tag: ${{UNILEAF_VERSION}}
                build_arguments:
                    - UNILEAF_VERSION=${{UNILEAF_VERSION}}
                    - PYTHON_VERSION=${{DEFAULT_NEUROAI_PYTHON_VERSION}}
                dockerfile: "backend/dataprofiler/Dockerfile"
                buildkit: true
                progress: "plain"
                secrets:
                    - id=with_creds_requirements,src=${{DATA_PROFILER_WITH_CREDS_REQUIREMENTS}}

            python-mdserver-build:
                title: Build python mdserver Docker image
                type: build
                dockerfile: backend/pmdserver/Dockerfile
                tag: ${{UNILEAF_VERSION}}
                build_arguments:
                    - UNILEAF_VERSION=${{UNILEAF_VERSION}}
                    - PYTHON_VERSION=${{DEFAULT_NEUROAI_PYTHON_VERSION}}
                image_name: "leaf/unileaf-python-mdserver"
                buildkit: true
                progress: "plain"
                secrets:
                    - id=with_creds_requirements,src=${{PMDSERVER_WITH_CREDS_REQUIREMENTS}}

            agents:
                title: Build Agents server Docker image
                type: "build"
                # Donn: Needs updating when cluster takes up rename
                image_name: "leaf/unileaf-decision-assistant"
                tag: ${{UNILEAF_VERSION}}
                build_arguments:
                    - UNILEAF_VERSION=${{UNILEAF_VERSION}}
                    - PYTHON_VERSION=${{DEFAULT_NEUROAI_PYTHON_VERSION}}
                dockerfile: "backend/agents/deploy/Dockerfile"
                buildkit: true
                progress: "plain"
                secrets:
                    - id=with_creds_requirements,src=${{AGENTS_WITH_CREDS_REQUIREMENTS}}

            analytics-chat:
                title: Build Analytics Chat server Docker image
                type: "build"
                image_name: "leaf/unileaf-analytics-chat"
                tag: ${{UNILEAF_VERSION}}
                build_arguments:
                    - UNILEAF_VERSION=${{UNILEAF_VERSION}}
                    - PYTHON_VERSION=${{DEFAULT_NEUROAI_PYTHON_VERSION}}
                    - GIT_VERSION=${{DEFAULT_NEUROAI_GIT_VERSION}}
                    - PANDAS_VERSION=${{PANDAS_VERSION}}
                dockerfile: "backend/analytics/service/Dockerfile"
                buildkit: true
                progress: "plain"
                secrets:
                    - id=with_creds_requirements,src=${{ANALYTICS_CHAT_WITH_CREDS_REQUIREMENTS}}

    clean_up:
        description: "Clean up after ourselves"
        type: "freestyle"
        image: alpine:3.13.1
        commands:
            # Clean up anything senstive we do not want to leak between builds
            - rm -rf ${{TEMP_DIR_OUTSIDE_CONTAINER}}
